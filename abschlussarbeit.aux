\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\citation{xiao2022tackling}
\citation{song2020score}
\citation{Zhang_2023}
\citation{mildenhallNERF}
\citation{pooleDreamfusion}
\citation{lin2023magic3d}
\citation{chen2023fantasia3d}
\citation{qian2023magic123}
\citation{long2023wonder3d}
\citation{kingmaVAE,rezendeVAE}
\citation{goodfellowGAN}
\citation{yangdiffusionSummary,hoDDPMs,sohlDDPM}
\citation{radfordCLIP}
\citation{rombachStableDiffusion}
\citation{mildenhallNERF}
\citation{shen2021DMTet}
\citation{M_ller_2022}
\citation{pooleDreamfusion}
\citation{lin2023magic3d}
\citation{chen2023fantasia3d}
\citation{qian2023magic123}
\citation{long2023wonder3d}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:introduction}{{1}{1}{}{}{}}
\newlabel{ch:introduction@cref}{{[chapter][1][]1}{[1][1][]1}}
\citation{xiao2022tackling}
\citation{xiao2022tackling}
\citation{xiao2022tackling}
\citation{kingmaVAE,rezendeVAE}
\citation{goodfellowGAN}
\citation{hoDDPMs,sohlDDPM}
\citation{song2019SGM}
\citation{song2020score,song2021maximum}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Basics}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:basics}{{2}{3}{}{}{}}
\newlabel{ch:basics@cref}{{[chapter][2][]2}{[1][3][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The Generative Learning Trilemma: Balancing Quality, Speed, and Diversity in Generative Models. Image taken from \citep  {xiao2022tackling}.}}{3}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:generativeTrilemma}{{1}{3}{}{}{}}
\newlabel{fig:generativeTrilemma@cref}{{[figure][1][]1}{[1][3][]3}}
\citation{radfordCLIP}
\citation{rombachStableDiffusion}
\citation{hintonCode,GoodfellowDeepLearning}
\citation{hintonCode}
\citation{GoodfellowDeepLearning}
\citation{michelucci2022introduction}
\citation{GoodfellowDeepLearning}
\citation{GoodfellowDeepLearning}
\citation{michelucci2022introduction}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Variational Autoencoders~--~VAEs}{4}{}\protected@file@percent }
\newlabel{VAEs}{{2.1}{4}{}{}{}}
\newlabel{VAEs@cref}{{[section][1][2]2.1}{[1][4][]4}}
\citation{GoodfellowDeepLearning}
\citation{doerschVAE}
\citation{GoodfellowDeepLearning}
\citation{GoodfellowDeepLearning}
\citation{GoodfellowDeepLearning}
\citation{kingmaVAE,higginsVAE}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Schematic of an Autoencoder: Demonstrating the process of dimensionality reduction to a latent vector and subsequent reconstruction, aiming to minimize reconstruction loss.}}{5}{}\protected@file@percent }
\newlabel{fig:figureAE}{{2}{5}{}{}{}}
\newlabel{fig:figureAE@cref}{{[figure][2][]2}{[1][5][]5}}
\citation{goodfellowGAN}
\citation{goodfellowGAN}
\citation{goodfellowGAN}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Functionality of a Variational Autoencoder: This figure illustrates the incorporation of a latent distribution, characterized by mean and standard deviation, for enhancing latent space regularization, enabling more effective and diverse data generation.}}{6}{}\protected@file@percent }
\newlabel{fig:figureVAE}{{3}{6}{}{}{}}
\newlabel{fig:figureVAE@cref}{{[figure][3][]3}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Generative Adversarial Networks~--~GANs}{6}{}\protected@file@percent }
\newlabel{GAN}{{2.2}{6}{}{}{}}
\newlabel{GAN@cref}{{[section][2][2]2.2}{[1][6][]6}}
\citation{goodfellowGAN}
\citation{goodfellowGAN}
\citation{GoodfellowDeepLearning}
\citation{goodfellowGAN}
\citation{brophyGAN}
\citation{brophyGAN}
\citation{brophyGAN}
\citation{salimansNIPS}
\citation{brophyGAN}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schematic representation of Generative Adversarial Networks showcasing the interaction between the generator and discriminator networks in generating new data.}}{7}{}\protected@file@percent }
\newlabel{fig:figureGAN}{{4}{7}{}{}{}}
\newlabel{fig:figureGAN@cref}{{[figure][4][]4}{[1][7][]7}}
\citation{yangdiffusionSummary}
\citation{hoDDPMs,sohlDDPM}
\citation{song2019SGM}
\citation{song2020score,song2021maximum}
\citation{sohlDDPM}
\citation{hoDDPMs}
\citation{yangdiffusionSummary,pooleDreamfusion}
\citation{martinez2023understanding}
\citation{sohlDDPM,hoDDPMs}
\citation{kingma2023variationalDM}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Diffusion models}{8}{}\protected@file@percent }
\newlabel{diffusion Models}{{2.3}{8}{}{}{}}
\newlabel{diffusion Models@cref}{{[section][3][2]2.3}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Denoising Diffusion Probabilistic Models}{8}{}\protected@file@percent }
\newlabel{DDPMs}{{2.3.1}{8}{}{}{}}
\newlabel{DDPMs@cref}{{[subsection][1][2,3]2.3.1}{[1][8][]8}}
\citation{martinez2023understanding}
\citation{martinez2023understanding}
\citation{martinez2023understanding}
\citation{yangdiffusionSummary}
\citation{martinez2023understanding}
\citation{hoDDPMs,martinez2023understanding}
\citation{yangdiffusionSummary}
\citation{yangdiffusionSummary}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Illustration of the Forward Diffusion Process in DDPMs: This figure demonstrates the gradual addition of Gaussian noise to an image over multiple steps. Each subsequent image from left to right shows an increased level of noise, culminating in the far-right image, which represents a state of pure noise.}}{9}{}\protected@file@percent }
\newlabel{fig:figureForwardProcess}{{5}{9}{}{}{}}
\newlabel{fig:figureForwardProcess@cref}{{[figure][5][]5}{[1][9][]9}}
\citation{martinez2023understanding}
\citation{song2019SGM}
\citation{steinScore}
\citation{song2019SGM}
\citation{hyvarinenScoreMatching}
\citation{song2021score}
\citation{song2021score}
\citation{song2019SGM}
\citation{robertsLangevin}
\citation{song2021score}
\citation{song2019SGM,song2021score}
\citation{song2019SGM}
\citation{song2019SGM}
\citation{song2019SGM}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Score-Based Generative Models}{10}{}\protected@file@percent }
\newlabel{SGMs}{{2.3.2}{10}{}{}{}}
\newlabel{SGMs@cref}{{[subsection][2][2,3]2.3.2}{[1][10][]10}}
\citation{song2019SGM}
\citation{song2019SGM}
\citation{song2020score}
\citation{song2020score}
\citation{song2020score}
\citation{anderson1982313}
\citation{song2020score}
\citation{song2020score}
\citation{song2019SGM}
\citation{song2020score}
\citation{song2020score}
\citation{hyvarinenScoreMatching}
\citation{song2020score}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Score-Based Generative Modeling through Stochastic Differential Equations~--~SDEs}{11}{}\protected@file@percent }
\newlabel{SDEs}{{2.3.3}{11}{}{}{}}
\newlabel{SDEs@cref}{{[subsection][3][2,3]2.3.3}{[1][11][]11}}
\citation{radfordCLIP}
\citation{radfordCLIP}
\citation{radfordCLIP}
\citation{radfordCLIP}
\citation{rombachStableDiffusion}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces This figure, adapted from Song et al.~\citep  {song2020score}, illustrates the two-fold process in score-based generative modeling through SDEs. On the left, the Forward SDE represents the gradual transformation of data into noise, guided by the drift and diffusion coefficients. On the right, the Reverse SDE depicts the process of reconstituting original data from noise, leveraging the known score of each marginal distribution.}}{12}{}\protected@file@percent }
\newlabel{fig:DM_SDEs}{{6}{12}{}{}{}}
\newlabel{fig:DM_SDEs@cref}{{[figure][6][]6}{[1][11][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Contrastive Language-Image Pre-training~--~CLIP}{12}{}\protected@file@percent }
\newlabel{CLIP}{{2.4}{12}{}{}{}}
\newlabel{CLIP@cref}{{[section][4][2]2.4}{[1][12][]12}}
\citation{rombachStableDiffusion}
\citation{ho2022classifier}
\citation{noriega2005multilayer,MurtaghMLP}
\citation{MurtaghMLP,noriega2005multilayer}
\citation{noriega2005multilayer}
\citation{MurtaghMLP}
\citation{MurtaghMLP}
\citation{lahav2020meshwalker,Zhang_2023}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Stable Diffusion}{13}{}\protected@file@percent }
\newlabel{stableDiffusion}{{2.5}{13}{}{}{}}
\newlabel{stableDiffusion@cref}{{[section][5][2]2.5}{[1][12][]13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Multilayer Perceptron~--~MLP}{13}{}\protected@file@percent }
\newlabel{MLP}{{2.6}{13}{}{}{}}
\newlabel{MLP@cref}{{[section][6][2]2.6}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Representation Forms of 3D Data}{13}{}\protected@file@percent }
\newlabel{3Drepresentation}{{2.7}{13}{}{}{}}
\newlabel{3Drepresentation@cref}{{[section][7][2]2.7}{[1][13][]13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Meshes, Point-Clouds and Voxels}{13}{}\protected@file@percent }
\newlabel{MPCV}{{2.7.1}{13}{}{}{}}
\newlabel{MPCV@cref}{{[subsection][1][2,7]2.7.1}{[1][13][]13}}
\citation{voxels,Zhang_2023}
\citation{voxels,Zhang_2023}
\citation{Zhang_2023}
\citation{Zhang_2023}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Representation forms of 3D data, adapted from Zhang et al.~\citep  {Zhang_2023}.}}{14}{}\protected@file@percent }
\newlabel{fig:mpcv}{{7}{14}{}{}{}}
\newlabel{fig:mpcv@cref}{{[figure][7][]7}{[1][14][]14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Neural Radiance Fields~--~NeRFs}{14}{}\protected@file@percent }
\newlabel{NeRF}{{2.7.2}{14}{}{}{}}
\newlabel{NeRF@cref}{{[subsection][2][2,7]2.7.2}{[1][14][]14}}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sumamrized workflow of a NeRF as shown in~\citep  {mildenhallNERF}: 5D input (Position + Direction) is processed by the MLP \(F_\theta \) to output color and density. Volume rendering integrates predictions along rays to generate an image from the specified viewpoint. The rendering loss, comparing the rendered and actual images, guides the network's training and refinement process.}}{15}{}\protected@file@percent }
\newlabel{fig:figureNeRF}{{8}{15}{}{}{}}
\newlabel{fig:figureNeRF@cref}{{[figure][8][]8}{[1][14][]15}}
\citation{hu2023consistentnerf}
\citation{mildenhallNERF}
\citation{arandjelović2021nerf}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{mildenhallNERF}
\citation{rabby2023beyondpixels}
\citation{rabby2023beyondpixels}
\citation{shen2021DMTet}
\citation{mildenhallNERF}
\citation{michalkiewicz2019deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Deep Marching Tetraheda~--~DMTet}{16}{}\protected@file@percent }
\newlabel{DMTet}{{2.7.3}{16}{}{}{}}
\newlabel{DMTet@cref}{{[subsection][3][2,7]2.7.3}{[1][16][]16}}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{shen2021DMTet}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{M_ller_2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}Instant Neual Graphics Primitives}{17}{}\protected@file@percent }
\newlabel{InstantNGP}{{2.7.4}{17}{}{}{}}
\newlabel{InstantNGP@cref}{{[subsection][4][2,7]2.7.4}{[1][17][]17}}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{M_ller_2022}
\citation{pooleDreamfusion}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Models}{19}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:models}{{3}{19}{}{}{}}
\newlabel{ch:models@cref}{{[chapter][3][]3}{[1][19][]19}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Timeline of generative 3D modeling technologies: This figure outlines important milestones in the development of the key methods discussed in this thesis.}}{19}{}\protected@file@percent }
\newlabel{fig:timelineMethods}{{9}{19}{}{}{}}
\newlabel{fig:timelineMethods@cref}{{[figure][9][]9}{[1][19][]19}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}3D from Text input}{19}{}\protected@file@percent }
\newlabel{3d from text}{{3.1}{19}{}{}{}}
\newlabel{3d from text@cref}{{[section][1][3]3.1}{[1][19][]19}}
\citation{mordvintsevDIP}
\citation{pooleDreamfusion}
\citation{saharia2022imagen}
\citation{barron2022mipnerf}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Dreamfusion}{20}{}\protected@file@percent }
\newlabel{dreamfusion}{{3.1.1}{20}{}{}{}}
\newlabel{dreamfusion@cref}{{[subsection][1][3,1]3.1.1}{[1][19][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Overview of DreamFusion's process for transforming text into 3D models, illustrating the integration of Neural Radiance Fields, Score Distillation Sampling, and diffusion models. Image adapted from Poole et al.~\citep  {pooleDreamfusion}.}}{20}{}\protected@file@percent }
\newlabel{fig:figureDreamfusion}{{10}{20}{}{}{}}
\newlabel{fig:figureDreamfusion@cref}{{[figure][10][]10}{[1][20][]20}}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{lin2023magic3d}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{pooleDreamfusion}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{balaji2022eDiff-I}
\citation{saharia2022imagen}
\citation{lin2023magic3d}
\citation{M_ller_2022}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{shen2021DMTet,lin2023magic3d}
\citation{rombachStableDiffusion}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Magic3D}{22}{}\protected@file@percent }
\newlabel{magic3D}{{3.1.2}{22}{}{}{}}
\newlabel{magic3D@cref}{{[subsection][2][3,1]3.1.2}{[1][21][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces This illustration from \citep  {lin2023magic3d} showcases the Magic3D process, beginning with the InstantNGP for initial 3D representation. It then details the coarse-to-fine procedure, evolving to a refined high-resolution 3D mesh model.}}{22}{}\protected@file@percent }
\newlabel{fig:figureMagic}{{11}{22}{}{}{}}
\newlabel{fig:figureMagic@cref}{{[figure][11][]11}{[1][22][]22}}
\citation{lin2023magic3d}
\citation{lin2023magic3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{mcauley2012practical}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Fantasia3D}{23}{}\protected@file@percent }
\newlabel{fantasia3D}{{3.1.3}{23}{}{}{}}
\newlabel{fantasia3D@cref}{{[subsection][3][3,1]3.1.3}{[1][23][]23}}
\citation{rombachStableDiffusion}
\citation{mildenhallNERF}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{chen2023fantasia3d}
\citation{qian2023magic123}
\citation{qian2023magic123}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Overview of Fantasia3D's workflow as given in \citep  {chen2023fantasia3d}, disentangling geometry from appearance modeling and iteratively enhancing the quality using a refinment process.}}{24}{}\protected@file@percent }
\newlabel{fig:figureFantasia}{{12}{24}{}{}{}}
\newlabel{fig:figureFantasia@cref}{{[figure][12][]12}{[1][23][]24}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}3D from Image}{24}{}\protected@file@percent }
\newlabel{3d from image}{{3.2}{24}{}{}{}}
\newlabel{3d from image@cref}{{[section][2][3]3.2}{[1][24][]24}}
\citation{ranftl2021vision}
\citation{ranftl2020robust}
\citation{qian2023magic123}
\citation{qian2023magic123}
\citation{qian2023magic123}
\citation{rombachStableDiffusion}
\citation{qian2023magic123}
\citation{qian2023magic123}
\citation{qian2023magic123,shen2021DMTet}
\citation{liu2023zero1to3}
\citation{qian2023magic123}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Magic 123}{25}{}\protected@file@percent }
\newlabel{Magic123}{{3.2.1}{25}{}{}{}}
\newlabel{Magic123@cref}{{[subsection][1][3,2]3.2.1}{[1][24][]25}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Overview of Magic123's two-stage process, which starts with the initial image and illustrates the transition from coarse geometry capture with Instant-NGP to high-resolution mesh refinement using DMTet. Image taken from \citep  {qian2023magic123}.}}{25}{}\protected@file@percent }
\newlabel{fig:figureMagic123}{{13}{25}{}{}{}}
\newlabel{fig:figureMagic123@cref}{{[figure][13][]13}{[1][25][]25}}
\citation{qian2023magic123}
\citation{qian2023magic123}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{radfordCLIP}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Wonder 3D}{26}{}\protected@file@percent }
\newlabel{Wonder3D}{{3.2.2}{26}{}{}{}}
\newlabel{Wonder3D@cref}{{[subsection][2][3,2]3.2.2}{[1][26][]26}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces This Figure adapted from Long et al.~\citep  {long2023wonder3d} summarizes the functionality of Wonder3D, illustrating its unique approach in generating textured meshes from single images using cross-domain diffusion models.}}{26}{}\protected@file@percent }
\newlabel{fig:Wonder3D}{{14}{26}{}{}{}}
\newlabel{fig:Wonder3D@cref}{{[figure][14][]14}{[1][26][]26}}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{long2023wonder3d}
\citation{threestudio2023}
\citation{qian2023magic123}
\citation{googlecolab}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Comparative Study}{28}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:comparative study}{{4}{28}{}{}{}}
\newlabel{ch:comparative study@cref}{{[chapter][4][]4}{[1][28][]28}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experimental Setup}{28}{}\protected@file@percent }
\newlabel{Setup}{{4.1}{28}{}{}{}}
\newlabel{Setup@cref}{{[section][1][4]4.1}{[1][28][]28}}
\citation{long2023wonder3d}
\citation{dalle3,Dall-E-3}
\citation{stable-dreamfusion}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Individual Generation Process}{29}{}\protected@file@percent }
\newlabel{generationProcess}{{4.2}{29}{}{}{}}
\newlabel{generationProcess@cref}{{[section][2][4]4.2}{[1][29][]29}}
\citation{meshLab}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The generation process of Dreamfusion using the prompt ``a robot made out of plants''. Section (c) shows a snapshot of the final mesh generated.}}{30}{}\protected@file@percent }
\newlabel{fig:generationDreamFusion}{{15}{30}{}{}{}}
\newlabel{fig:generationDreamFusion@cref}{{[figure][15][]15}{[1][30][]30}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Magic3D generation process from coarse (a, b) to fine (c, d)}}{31}{}\protected@file@percent }
\newlabel{fig:generationMagic3D}{{16}{31}{}{}{}}
\newlabel{fig:generationMagic3D@cref}{{[figure][16][]16}{[1][31][]31}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Magic3D also generates an albedo during training. The right side shows the extracted mesh.}}{32}{}\protected@file@percent }
\newlabel{fig:texturesMagic3D}{{17}{32}{}{}{}}
\newlabel{fig:texturesMagic3D@cref}{{[figure][17][]17}{[1][32][]32}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces a: Fantasia3D starting with only a perfect square and refining this according to the prompt ``a robot made out of plants''. In b: only the appearance of the model gets refined. Image c shows the rendered model }}{33}{}\protected@file@percent }
\newlabel{fig:generationFantasia}{{18}{33}{}{}{}}
\newlabel{fig:generationFantasia@cref}{{[figure][18][]18}{[1][32][]33}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Generated textures from Fantasia3D\spacefactor \@m {}; from left to right: diffuse, roughness, metallic, and normal.}}{34}{}\protected@file@percent }
\newlabel{fig:texturesFantasia}{{19}{34}{}{}{}}
\newlabel{fig:texturesFantasia@cref}{{[figure][19][]19}{[1][34][]34}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Front view of the coarse stage of Magic123}}{34}{}\protected@file@percent }
\newlabel{fig:generationFrontCoarseMagic123}{{20}{34}{}{}{}}
\newlabel{fig:generationFrontCoarseMagic123@cref}{{[figure][20][]20}{[1][34][]34}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Front view of the refine stage of Magic123}}{35}{}\protected@file@percent }
\newlabel{fig:generationFrontRefineMagic123}{{21}{35}{}{}{}}
\newlabel{fig:generationFrontRefineMagic123@cref}{{[figure][21][]21}{[1][35][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces 3D models generated by Magic123 and Wonder3D based on an imput image}}{36}{}\protected@file@percent }
\newlabel{fig:inputAndModel}{{22}{36}{}{}{}}
\newlabel{fig:inputAndModel@cref}{{[figure][22][]22}{[1][36][]36}}
\citation{trimesh}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Front view of the Wonder3D generation process. Only minor changes can be seen between initialization and iteration 10000.}}{37}{}\protected@file@percent }
\newlabel{fig:generationWonder3D}{{23}{37}{}{}{}}
\newlabel{fig:generationWonder3D@cref}{{[figure][23][]23}{[1][36][]37}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Comparative Analysis}{37}{}\protected@file@percent }
\newlabel{comparativeAnalysis}{{4.3}{37}{}{}{}}
\newlabel{comparativeAnalysis@cref}{{[section][3][4]4.3}{[1][37][]37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Subjective Evaluation}{38}{}\protected@file@percent }
\newlabel{subjective}{{4.3.1}{38}{}{}{}}
\newlabel{subjective@cref}{{[subsection][1][4,3]4.3.1}{[1][38][]38}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Results obtained using the prompt ``a high-quality rendering of a Playmobil firefighter''.}}{38}{}\protected@file@percent }
\newlabel{fig:resultPlaymobil}{{24}{38}{}{}{}}
\newlabel{fig:resultPlaymobil@cref}{{[figure][24][]24}{[1][38][]38}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces (a) displays the original image for the playmobil figure derived form Dall-E 3; (b) and (c) show the side and back view of Magic123, resectively.}}{39}{}\protected@file@percent }
\newlabel{fig:inputPlaymobil}{{25}{39}{}{}{}}
\newlabel{fig:inputPlaymobil@cref}{{[figure][25][]25}{[1][39][]39}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Results obtained using the prompt ``a rendering of a highly symmetrical loaf of bread''. Part (f) is the input image for Magic123 and Wonder3D, generated with Dall-E 3}}{40}{}\protected@file@percent }
\newlabel{fig:resultBread}{{26}{40}{}{}{}}
\newlabel{fig:resultBread@cref}{{[figure][26][]26}{[1][40][]40}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces The front view of the generated objects with the prompt ``a high-quality rendering of a big dog sleeping on a chair''.}}{42}{}\protected@file@percent }
\newlabel{fig:resultDogFront}{{27}{42}{}{}{}}
\newlabel{fig:resultDogFront@cref}{{[figure][27][]27}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces The back view of the prompt ``a high-quality rendering of a big dog sleeping on a chair''}}{43}{}\protected@file@percent }
\newlabel{fig:resultDogBack}{{28}{43}{}{}{}}
\newlabel{fig:resultDogBack@cref}{{[figure][28][]28}{[1][42][]43}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Results obtained using the prompt ``a high-quality rendering of a fern in a wooden pot''.}}{44}{}\protected@file@percent }
\newlabel{fig:resultFern}{{29}{44}{}{}{}}
\newlabel{fig:resultFern@cref}{{[figure][29][]29}{[1][43][]44}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Part (a) shows the result of the coarse stage of Magic3D, where the actual fern was still present; (b and c) show the side view of the fern showcasing the limitations of Magic123 in deriving the correct angles in contrast to Wonder3D}}{45}{}\protected@file@percent }
\newlabel{fig:fernSideview}{{30}{45}{}{}{}}
\newlabel{fig:fernSideview@cref}{{[figure][30][]30}{[1][44][]45}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Using the Prompt ``a detailed rendering of a snow globe containing a snowman'' to assess transparency and difficult reflections between various methods.}}{46}{}\protected@file@percent }
\newlabel{fig:resultGlobe}{{31}{46}{}{}{}}
\newlabel{fig:resultGlobe@cref}{{[figure][31][]31}{[1][45][]46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Technical Review}{47}{}\protected@file@percent }
\newlabel{technical}{{4.3.2}{47}{}{}{}}
\newlabel{technical@cref}{{[subsection][2][4,3]4.3.2}{[1][47][]47}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of Generation Times for Different Prompts Across Methods (Hours:Minutes). Legend: C = Coarse, R = Refine, Geom = Geometry, Appear = Appearance.}}{47}{}\protected@file@percent }
\newlabel{table:generation_times_complex}{{1}{47}{}{}{}}
\newlabel{table:generation_times_complex@cref}{{[table][1][]1}{[1][47][]47}}
\citation{radfordCLIP}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces CLIP-scores for Playmobil firefighter models based on different prompts.}}{49}{}\protected@file@percent }
\newlabel{table:scorePlaymobil}{{2}{49}{}{}{}}
\newlabel{table:scorePlaymobil@cref}{{[table][2][]2}{[1][48][]49}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Symmetrie-scores for bread models demanding a symmetrical output.}}{49}{}\protected@file@percent }
\newlabel{table:symmetrieBread}{{3}{49}{}{}{}}
\newlabel{table:symmetrieBread@cref}{{[table][3][]3}{[1][49][]49}}
\citation{LumaAIGenie2023}
\citation{kerbl3Dgaussians}
\citation{LumaAIGenie2023}
\citation{Midjourney2023}
\citation{discord}
\citation{kerbl3Dgaussians}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Future Directions}{50}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:future}{{5}{50}{}{}{}}
\newlabel{ch:future@cref}{{[chapter][5][]5}{[1][50][]50}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Emerging Trends and Future Directions}{50}{}\protected@file@percent }
\citation{luccioni2023stable,radfordCLIP}
\citation{buolamwini2018gender}
\citation{luccioni2023stable}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Handle Generative Bias}{51}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{53}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusion}{{6}{53}{}{}{}}
\newlabel{ch:conclusion@cref}{{[chapter][6][]6}{[1][53][]53}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary of Findings}{53}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Contributions to the Field}{54}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Implications and Practical Applications}{54}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Additional Images}{55}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:additionalImages}{{A}{55}{}{}{}}
\newlabel{ch:additionalImages@cref}{{[appendix][1][2147483647]A}{[1][55][]55}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces The generation process of DreamFusion using the prompt ``a robot made out of plants'' a second time.}}{55}{}\protected@file@percent }
\newlabel{fig:secondRobotDreamfusion}{{32}{55}{}{}{}}
\newlabel{fig:secondRobotDreamfusion@cref}{{[figure][32][2147483647]32}{[1][55][]55}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Initializing Fantasia3D with a coarse mesh representing a basic human figure}}{56}{}\protected@file@percent }
\newlabel{fig:generationFantasia2}{{33}{56}{}{}{}}
\newlabel{fig:generationFantasia2@cref}{{[figure][33][2147483647]33}{[1][55][]56}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces The coarse in Magic123; From top to bottom: right, back and left view}}{57}{}\protected@file@percent }
\newlabel{fig:generationCoarseMagic123}{{34}{57}{}{}{}}
\newlabel{fig:generationCoarseMagic123@cref}{{[figure][34][2147483647]34}{[1][55][]57}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces The refine in Magic123; From top to bottom: right, back and left view}}{58}{}\protected@file@percent }
\newlabel{fig:generationRefineMagic123}{{35}{58}{}{}{}}
\newlabel{fig:generationRefineMagic123@cref}{{[figure][35][2147483647]35}{[1][55][]58}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Wonder3D initialization of multi-view color images and normals; (a) front, (b) front left, (c) left, (d) back, (e) right, (f) front right}}{59}{}\protected@file@percent }
\newlabel{fig:initializationWonder3D}{{36}{59}{}{}{}}
\newlabel{fig:initializationWonder3D@cref}{{[figure][36][2147483647]36}{[1][55][]59}}
\citation{threestudio2023}
\citation{chen2023fantasia3d}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Adaptive Modifications in Threestudio Implementations}{60}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:differences}{{B}{60}{}{}{}}
\newlabel{ch:differences@cref}{{[appendix][2][2147483647]B}{[1][60][]60}}
\bibstyle{apalike}
\bibdata{bibl}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{61}{}\protected@file@percent }
\bibcite{anderson1982313}{{1}{1982}{{Anderson}}{{}}}
\bibcite{arandjelović2021nerf}{{2}{2021}{{Arandjelovi{\'c} and Zisserman}}{{}}}
\bibcite{balaji2022eDiff-I}{{3}{2022}{{Balaji et~al.}}{{}}}
\bibcite{barron2022mipnerf}{{4}{2022}{{Barron et~al.}}{{}}}
\bibcite{Dall-E-3}{{5}{2023}{{Betker et~al.}}{{}}}
\bibcite{brophyGAN}{{6}{2023}{{Brophy et~al.}}{{}}}
\bibcite{buolamwini2018gender}{{7}{2018}{{Buolamwini and Gebru}}{{}}}
\bibcite{chen2023fantasia3d}{{8}{2023}{{Chen et~al.}}{{}}}
\bibcite{meshLab}{{9}{2008}{{Cignoni et~al.}}{{}}}
\bibcite{discord}{{10}{2023}{{Discord Inc.}}{{}}}
\bibcite{doerschVAE}{{11}{2016}{{Doersch}}{{}}}
\bibcite{goodfellowGAN}{{12}{2020}{{Goodfellow et~al.}}{{}}}
\bibcite{GoodfellowDeepLearning}{{13}{2016}{{Goodfellow et~al.}}{{}}}
\bibcite{googlecolab}{{14}{2023}{{Google LLC}}{{}}}
\bibcite{threestudio2023}{{15}{2023}{{Guo et~al.}}{{}}}
\bibcite{trimesh}{{16}{2019}{{Haggerty et~al.}}{{}}}
\bibcite{higginsVAE}{{17}{2017}{{Higgins et~al.}}{{}}}
\bibcite{hintonCode}{{18}{2006}{{Hinton and Salakhutdinov}}{{}}}
\bibcite{hoDDPMs}{{19}{2020}{{Ho et~al.}}{{}}}
\bibcite{ho2022classifier}{{20}{2022}{{Ho and Salimans}}{{}}}
\bibcite{hu2023consistentnerf}{{21}{2023}{{Hu et~al.}}{{}}}
\bibcite{hyvarinenScoreMatching}{{22}{2005}{{Hyv{\"a}rinen and Dayan}}{{}}}
\bibcite{LumaAIGenie2023}{{23}{2023}{{Jain et~al.}}{{}}}
\bibcite{kerbl3Dgaussians}{{24}{2023}{{Kerbl et~al.}}{{}}}
\bibcite{kingma2023variationalDM}{{25}{2021}{{Kingma et~al.}}{{}}}
\bibcite{kingmaVAE}{{26}{2013}{{Kingma and Welling}}{{}}}
\bibcite{lahav2020meshwalker}{{27}{2020}{{Lahav and Tal}}{{}}}
\bibcite{lin2023magic3d}{{28}{2023}{{Lin et~al.}}{{}}}
\bibcite{steinScore}{{29}{2016}{{Liu et~al.}}{{}}}
\bibcite{liu2023zero1to3}{{30}{2023}{{Liu et~al.}}{{}}}
\bibcite{long2023wonder3d}{{31}{2023}{{Long et~al.}}{{}}}
\bibcite{luccioni2023stable}{{32}{2023}{{Luccioni et~al.}}{{}}}
\bibcite{martinez2023understanding}{{33}{2023}{{Mart{\'\i }nez et~al.}}{{}}}
\bibcite{mcauley2012practical}{{34}{2012}{{McAuley et~al.}}{{}}}
\bibcite{michalkiewicz2019deep}{{35}{2019}{{Michalkiewicz et~al.}}{{}}}
\bibcite{michelucci2022introduction}{{36}{2022}{{Michelucci}}{{}}}
\bibcite{Midjourney2023}{{37}{2023}{{Midjourney}}{{}}}
\bibcite{mildenhallNERF}{{38}{2021}{{Mildenhall et~al.}}{{}}}
\bibcite{mordvintsevDIP}{{39}{2018}{{Mordvintsev et~al.}}{{}}}
\bibcite{M_ller_2022}{{40}{2022}{{M{\"u}ller et~al.}}{{}}}
\bibcite{MurtaghMLP}{{41}{1991}{{Murtagh}}{{}}}
\bibcite{noriega2005multilayer}{{42}{2005}{{Noriega}}{{}}}
\bibcite{pooleDreamfusion}{{43}{2022}{{Poole et~al.}}{{}}}
\bibcite{qian2023magic123}{{44}{2023}{{Qian et~al.}}{{}}}
\bibcite{rabby2023beyondpixels}{{45}{2023}{{Rabby and Zhang}}{{}}}
\bibcite{radfordCLIP}{{46}{2021}{{Radford et~al.}}{{}}}
\bibcite{dalle3}{{47}{2023}{{Ramesh et~al.}}{{}}}
\bibcite{ranftl2021vision}{{48}{2021}{{Ranftl et~al.}}{{}}}
\bibcite{ranftl2020robust}{{49}{2020}{{Ranftl et~al.}}{{}}}
\bibcite{rezendeVAE}{{50}{2014}{{Rezende et~al.}}{{}}}
\bibcite{robertsLangevin}{{51}{1996}{{Roberts and Tweedie}}{{}}}
\bibcite{rombachStableDiffusion}{{52}{2022}{{Rombach et~al.}}{{}}}
\bibcite{saharia2022imagen}{{53}{2022}{{Saharia et~al.}}{{}}}
\bibcite{salimansNIPS}{{54}{2016}{{Salimans et~al.}}{{}}}
\bibcite{shen2021DMTet}{{55}{2021}{{Shen et~al.}}{{}}}
\bibcite{sohlDDPM}{{56}{2015}{{Sohl-Dickstein et~al.}}{{}}}
\bibcite{song2021score}{{57}{2021}{{Song}}{{}}}
\bibcite{song2021maximum}{{58}{2021}{{Song et~al.}}{{}}}
\bibcite{song2019SGM}{{59}{2019}{{Song and Ermon}}{{}}}
\bibcite{song2020score}{{60}{2020}{{Song et~al.}}{{}}}
\bibcite{stable-dreamfusion}{{61}{2022}{{Tang}}{{}}}
\bibcite{xiao2022tackling}{{62}{2021}{{Xiao et~al.}}{{}}}
\bibcite{voxels}{{63}{2021}{{Xu et~al.}}{{}}}
\bibcite{yangdiffusionSummary}{{64}{2022}{{Yang et~al.}}{{}}}
\bibcite{Zhang_2023}{{65}{2023}{{Zhang et~al.}}{{}}}
\gdef \@abspage@last{75}
