\begin{thebibliography}{}

\bibitem[Anderson, 1982]{anderson1982313}
Anderson, B.~D. (1982).
\newblock Reverse-time diffusion equation models.
\newblock {\em Stochastic Processes and their Applications}, 12(3):313--326.

\bibitem[Arandjelović and Zisserman, 2021]{arandjelović2021nerf}
Arandjelović, R. and Zisserman, A. (2021).
\newblock Nerf in detail: Learning to sample for view synthesis.

\bibitem[Balaji et~al., 2022]{balaji2022eDiff-I}
Balaji, Y., Nah, S., Huang, X., Vahdat, A., Song, J., Zhang, Q., Kreis, K.,
  Aittala, M., Aila, T., Laine, S., Catanzaro, B., Karras, T., and Liu, M.-Y.
  (2022).
\newblock ediff-i: Text-to-image diffusion models with ensemble of expert
  denoisers.
\newblock {\em arXiv preprint arXiv:2211.01324}.

\bibitem[Barron et~al., 2022]{barron2022mipnerf}
Barron, J.~T., Mildenhall, B., Verbin, D., Srinivasan, P.~P., and Hedman, P.
  (2022).
\newblock Mip-nerf 360: Unbounded anti-aliased neural radiance fields.

\bibitem[Brophy et~al., 2023]{brophyGAN}
Brophy, E., Wang, Z., She, Q., and Ward, T. (2023).
\newblock Generative adversarial networks in time series: A systematic
  literature review.
\newblock {\em ACM Computing Surveys}, 55(10):1--31.

\bibitem[Chen et~al., 2023]{chen2023fantasia3d}
Chen, R., Chen, Y., Jiao, N., and Jia, K. (2023).
\newblock Fantasia3d: Disentangling geometry and appearance for high-quality
  text-to-3d content creation.

\bibitem[Cignoni et~al., 2008]{meshLab}
Cignoni, P., Callieri, M., Corsini, M., Dellepiane, M., Ganovelli, F., and
  Ranzuglia, G. (2008).
\newblock {MeshLab: an Open-Source Mesh Processing Tool}.
\newblock In Scarano, V., Chiara, R.~D., and Erra, U., editors, {\em
  Eurographics Italian Chapter Conference}. The Eurographics Association.

\bibitem[{Dawson-Haggerty et al.}, 2019]{trimesh}
{Dawson-Haggerty et al.} (2019).
\newblock trimesh.

\bibitem[Doersch, 2016]{doerschVAE}
Doersch, C. (2016).
\newblock Tutorial on variational autoencoders.
\newblock {\em arXiv preprint arXiv:1606.05908}.

\bibitem[Dosovitskiy et~al., 2021]{dosovitskiyViT}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N. (2021).
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.

\bibitem[Goodfellow et~al., 2020]{goodfellowGAN}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y. (2020).
\newblock Generative adversarial networks.
\newblock {\em Communications of the ACM}, 63(11):139--144.

\bibitem[Goodfellow et~al., 2016]{GoodfellowDeepLearning}
Goodfellow, I.~J., Bengio, Y., and Courville, A. (2016).
\newblock {\em Deep Learning}.
\newblock MIT Press, Cambridge, MA, USA.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem[{Google LLC}, 2023]{googlecolab}
{Google LLC} (2023).
\newblock Google colaboratory.
\newblock \url{https://colab.research.google.com/}.
\newblock Accessed: [1.11.2023].

\bibitem[Guo et~al., 2023]{threestudio2023}
Guo, Y.-C., Liu, Y.-T., Shao, R., Laforte, C., Voleti, V., Luo, G., Chen,
  C.-H., Zou, Z.-X., Wang, C., Cao, Y.-P., and Zhang, S.-H. (2023).
\newblock threestudio: A unified framework for 3d content generation.
\newblock \url{https://github.com/threestudio-project/threestudio}.

\bibitem[He et~al., 2016]{heResnet}
He, K., Zhang, X., Ren, S., and Sun, J. (2016).
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}.

\bibitem[Higgins et~al., 2017]{higginsVAE}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A. (2017).
\newblock beta-{VAE}: Learning basic visual concepts with a constrained
  variational framework.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Hinton and Salakhutdinov, 2006]{hintonCode}
Hinton, G.~E. and Salakhutdinov, R.~R. (2006).
\newblock Reducing the dimensionality of data with neural networks.
\newblock {\em science}, 313(5786):504--507.

\bibitem[Ho et~al., 2020]{hoDDPMs}
Ho, J., Jain, A., and Abbeel, P. (2020).
\newblock Denoising diffusion probabilistic models.
\newblock {\em ArXiv}, abs/2006.11239.

\bibitem[Hu et~al., 2023]{hu2023consistentnerf}
Hu, S., Zhou, K., Li, K., Yu, L., Hong, L., Hu, T., Li, Z., Lee, G.~H., and
  Liu, Z. (2023).
\newblock Consistentnerf: Enhancing neural radiance fields with 3d consistency
  for sparse view synthesis.

\bibitem[Hyv{\"a}rinen and Dayan, 2005]{hyvarinenScoreMatching}
Hyv{\"a}rinen, A. and Dayan, P. (2005).
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6(4).

\bibitem[Kingma et~al., 2023]{kingma2023variationalDM}
Kingma, D.~P., Salimans, T., Poole, B., and Ho, J. (2023).
\newblock Variational diffusion models.

\bibitem[Kingma and Welling, 2022]{kingmaVAE}
Kingma, D.~P. and Welling, M. (2022).
\newblock Auto-encoding variational bayes.

\bibitem[Lahav and Tal, 2020]{lahav2020meshwalker}
Lahav, A. and Tal, A. (2020).
\newblock Meshwalker: Deep mesh understanding by random walks.

\bibitem[Lin et~al., 2023]{lin2023magic3d}
Lin, C.-H., Gao, J., Tang, L., Takikawa, T., Zeng, X., Huang, X., Kreis, K.,
  Fidler, S., Liu, M.-Y., and Lin, T.-Y. (2023).
\newblock Magic3d: High-resolution text-to-3d content creation.

\bibitem[Liu et~al., 2016]{steinScore}
Liu, Q., Lee, J., and Jordan, M. (2016).
\newblock A kernelized stein discrepancy for goodness-of-fit tests.
\newblock In Balcan, M.~F. and Weinberger, K.~Q., editors, {\em Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of {\em
  Proceedings of Machine Learning Research}, pages 276--284, New York, New
  York, USA. PMLR.

\bibitem[Liu et~al., 2023]{liu2023zero1to3}
Liu, R., Wu, R., Hoorick, B.~V., Tokmakov, P., Zakharov, S., and Vondrick, C.
  (2023).
\newblock Zero-1-to-3: Zero-shot one image to 3d object.

\bibitem[Long et~al., 2023]{long2023wonder3d}
Long, X., Guo, Y.-C., Lin, C., Liu, Y., Dou, Z., Liu, L., Ma, Y., Zhang, S.-H.,
  Habermann, M., Theobalt, C., and Wang, W. (2023).
\newblock Wonder3d: Single image to 3d using cross-domain diffusion.

\bibitem[Martínez et~al., 2023]{martinez2023understanding}
Martínez, G., Watson, L., Reviriego, P., Hernández, J.~A., Juarez, M., and
  Sarkar, R. (2023).
\newblock Towards understanding the interplay of generative artificial
  intelligence and the internet.

\bibitem[Michalkiewicz et~al., 2019]{michalkiewicz2019deep}
Michalkiewicz, M., Pontes, J.~K., Jack, D., Baktashmotlagh, M., and Eriksson,
  A. (2019).
\newblock Deep level sets: Implicit surface representations for 3d shape
  inference.

\bibitem[Michelucci, 2022]{michelucci2022introduction}
Michelucci, U. (2022).
\newblock An introduction to autoencoders.

\bibitem[Mildenhall et~al., 2020]{mildenhallNERF}
Mildenhall, B., Srinivasan, P.~P., Tancik, M., Barron, J.~T., Ramamoorthi, R.,
  and Ng, R. (2020).
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In {\em ECCV}.

\bibitem[Mordvintsev et~al., 2018]{mordvintsevDIP}
Mordvintsev, A., Pezzotti, N., Schubert, L., and Olah, C. (2018).
\newblock Differentiable image parameterizations.
\newblock {\em Distill}, 3.

\bibitem[M\"uller et~al., 2022]{mueller2022instant}
M\"uller, T., Evans, A., Schied, C., and Keller, A. (2022).
\newblock Instant neural graphics primitives with a multiresolution hash
  encoding.
\newblock {\em ACM Trans. Graph.}, 41(4):102:1--102:15.

\bibitem[Murtagh, 1991]{MurtaghMLP}
Murtagh, F. (1991).
\newblock Multilayer perceptrons for classification and regression.
\newblock {\em Neurocomputing}, 2(5):183--197.

\bibitem[Müller et~al., 2022]{M_ller_2022}
Müller, T., Evans, A., Schied, C., and Keller, A. (2022).
\newblock Instant neural graphics primitives with a multiresolution hash
  encoding.
\newblock {\em ACM Transactions on Graphics}, 41(4):1–15.

\bibitem[Noriega, 2005]{noriega2005multilayer}
Noriega, L. (2005).
\newblock Multilayer perceptron tutorial.
\newblock {\em School of Computing. Staffordshire University}, 4(5):444.

\bibitem[Poole et~al., 2022]{pooleDreamfusion}
Poole, B., Jain, A., Barron, J.~T., and Mildenhall, B. (2022).
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock {\em arXiv preprint arXiv:2209.14988}.

\bibitem[Qian et~al., 2023]{qian2023magic123}
Qian, G., Mai, J., Hamdi, A., Ren, J., Siarohin, A., Li, B., Lee, H.-Y.,
  Skorokhodov, I., Wonka, P., Tulyakov, S., and Ghanem, B. (2023).
\newblock Magic123: One image to high-quality 3d object generation using both
  2d and 3d diffusion priors.

\bibitem[Rabby and Zhang, 2023]{rabby2023beyondpixels}
Rabby, A. S.~A. and Zhang, C. (2023).
\newblock Beyondpixels: A comprehensive review of the evolution of neural
  radiance fields.

\bibitem[Radford et~al., 2021]{radfordCLIP}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.
  (2021).
\newblock Learning transferable visual models from natural language
  supervision.

\bibitem[Ramesh et~al., 2023]{dalle3}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., et~al. (2023).
\newblock Dall-e 3.
\newblock \url{https://openai.com/dall-e-3}.
\newblock Accessed: [25.11.2023].

\bibitem[Ranftl et~al., 2021]{ranftl2021vision}
Ranftl, R., Bochkovskiy, A., and Koltun, V. (2021).
\newblock Vision transformers for dense prediction.

\bibitem[Ranftl et~al., 2020]{ranftl2020robust}
Ranftl, R., Lasinger, K., Hafner, D., Schindler, K., and Koltun, V. (2020).
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.

\bibitem[Rezende et~al., 2014]{rezendeVAE}
Rezende, D.~J., Mohamed, S., and Wierstra, D. (2014).
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.

\bibitem[Roberts and Tweedie, 1996]{robertsLangevin}
Roberts, G.~O. and Tweedie, R.~L. (1996).
\newblock Exponential convergence of langevin distributions and their discrete
  approximations.
\newblock {\em Bernoulli}, pages 341--363.

\bibitem[Rombach et~al., 2021]{rombachStableDiffusion}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2021).
\newblock High-resolution image synthesis with latent diffusion models.

\bibitem[Saharia et~al., 2022]{saharia2022imagen}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour,
  S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., Salimans, T., Ho, J.,
  Fleet, D.~J., and Norouzi, M. (2022).
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.

\bibitem[Salimans et~al., 2016]{salimansNIPS}
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.,
  and Chen, X. (2016).
\newblock Improved techniques for training gans.
\newblock In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R.,
  editors, {\em Advances in Neural Information Processing Systems}, volume~29.
  Curran Associates, Inc.

\bibitem[Shen et~al., 2021]{shen2021DMTet}
Shen, T., Gao, J., Yin, K., Liu, M.-Y., and Fidler, S. (2021).
\newblock Deep marching tetrahedra: a hybrid representation for high-resolution
  3d shape synthesis.

\bibitem[Sohl-Dickstein et~al., 2015]{sohlDDPM}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S. (2015).
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International conference on machine learning}, pages
  2256--2265. PMLR.

\bibitem[Song, 2021]{song2021score}
Song, Y. (2021).
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \url{https://yang-song.net/blog/2021/score/}.
\newblock Accessed: [26.11.2023].

\bibitem[Song et~al., 2021]{song2021maximum}
Song, Y., Durkan, C., Murray, I., and Ermon, S. (2021).
\newblock Maximum likelihood training of score-based diffusion models.
\newblock {\em Advances in Neural Information Processing Systems},
  34:1415--1428.

\bibitem[Song and Ermon, 2019]{song2019SGM}
Song, Y. and Ermon, S. (2019).
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Song et~al., 2020]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B. (2020).
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456}.

\bibitem[Tang, 2022]{stable-dreamfusion}
Tang, J. (2022).
\newblock Stable-dreamfusion: Text-to-3d with stable-diffusion.
\newblock https://github.com/ashawkey/stable-dreamfusion.

\bibitem[Vaswani et~al., 2023]{vaswani2023attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I. (2023).
\newblock Attention is all you need.

\bibitem[Xiao et~al., 2022]{xiao2022tackling}
Xiao, Z., Kreis, K., and Vahdat, A. (2022).
\newblock Tackling the generative learning trilemma with denoising diffusion
  gans.

\bibitem[Xu et~al., 2021]{voxels}
Xu, Y., Tong, X., and Stilla, U. (2021).
\newblock Voxel-based representation of 3d point clouds: Methods, applications,
  and its potential use in the construction industry.
\newblock {\em Automation in Construction}, 126:103675.

\bibitem[Yang et~al., 2022]{yangdiffusionSummary}
Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., Shao, Y., Zhang, W.,
  Cui, B., and Yang, M.-H. (2022).
\newblock Diffusion models: A comprehensive survey of methods and applications.
\newblock {\em arXiv preprint arXiv:2209.00796}.

\bibitem[Zhang et~al., 2023]{Zhang_2023}
Zhang, H., Wang, C., Tian, S., Lu, B., Zhang, L., Ning, X., and Bai, X. (2023).
\newblock Deep learning-based 3d point cloud classification: A systematic
  survey and outlook.
\newblock {\em Displays}, 79:102456.

\end{thebibliography}
