
Variational Autoencoders are built upon autoencoders, which consist of two parts. An encoder and a decoder. The encoder takes an input sample and converts its information into some vector (set of numbers) and the deoder takes this vector and expands it out to reconstruct the input sample. After an input is given, the encoder and decoder learn the parameters required to reconstruct the image/autio/... again. For Autoencoders, the output itself is not that important, rather the vector constructed in the middle. THis vecotr is important as it is a representation of the input image/audio/.. in its form such that the computer can understand. This vector can be fed to complex architectures to solve some problems. During testing time, only the decoder part is required as this is the part which generates the image. To do this, some vector is required. However, the nature of this vector is unknown. If the vector is given some random values, the resulting image will not be a good result (not even recognized). Thus, some method to determine this hidden vector is required. The idea is through sampling from a distribution. A Distribution could be seen as a pool of numbers (vectors). As example, the goal is to create a generative models to generate different animals. Thus, the model needs to learn a pool for each animal (cats, dogs, turtles, ... ). Each pool does not realy consist of an image of that corresponding animal, but rather of a vector representation of these images and they are only understood by the computer. -> Distribution can be seen as a pool of vectors. Sampling can be seen as "closing the eyes, reaching into the pool and picking one vector". If the location of such pool is known, then just go to the pool and pick the vector. (example: saying "I sample from the distribution of dog images", then its the same as saying "we picked a random vector from the dog pool"). However, the Problem with general autoencoders is, that we as humans, do not really know where these pools are. Picking a distribution which does not fit to any pool, the result will be garbage. So as a takeway on autoencoders, it is not possible to generate dog images because we do not know on how to assign values to the vector during the generation phase. Variational Autoencoders offer the opportunity to allow us to know on where to pick the right vector from. First, a region to constrain the universe is created. This region is constrained the region from which want to pick the vectors and within this region, the goal of the VAE is to find the pools (for each animal). This is done during training phase. During testing phase, all to be done to generate an image is to randomly sample a vector from this known region and then pass this vector to the generator part pf the VAE. This will create an image. A neat property about this region is that it is continuous, so there is the possibility to just alter some values in the vector to still get valid looking images.   