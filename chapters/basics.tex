\chapter{Basics}\label{ch:basics}

The chapter provides the groundwork necessary for the comparative analysis of automatic 3D model generation techniques by introducing the key technologies that drive these methods. It is essential to have a common understanding of the 2D generative models and 3D data representations that form the basis of this field.

The chapter begins by offering a brief overview of the most prevalent text-to-2D generative models, as they play a pivotal role in the process of 3D synthesis. This includes Variational Autoencoders (VAEs) \citep{kingmaVAE,rezendeVAE}, which are fundamental in providing probabilistic frameworks for learning complex data representations. Following this, Generative Adversarial Networks (GANs) \citep{goodfellowGAN} are introduced, emphasizing their unique training mechanics involving both generator and discriminator components. Additionally, the chapter explores the realm of Diffusion Models, with a specific focus on Denoising Diffusion Probabilistic Models (DDPMs) \citep{hoDDPMs,sohlDDPM}, while also touching upon Stochastic Gradient Methods (SGMs) \citep{song2019SGM} and Stochastic Differential Equations (SDEs) \citep{song2020score,song2021maximum}.

\begin{figure}[H]
  \centering
  \includegraphics[width=.4\columnwidth]{figures/BasicTrilemma.png}
  \caption{The Generative Learning Trilemma: Balancing Quality, Speed, and Diversity in Generative Models.~\citep{xiao2022tackling}}~\label{fig:generativeTrilemma}
\end{figure}

The figure above from \citeauthor{xiao2022tackling} illustrates the ``generative learning trilemma'', effectively capturing the trade-offs among high-quality sample generation, fast sampling, and mode coverage/diversity in these models. Generative Adversarial Networks are noted for their fast and high-quality samples, Denoising Diffusion Models excel in mode coverage/diversity and sample quality, and Variational Autoencoders balance between fast sampling and diversity in their outputs.

Furthermore, the chapter delves into Contrastive Language-Image Pre-training (CLIP) \citep{radfordCLIP}, illustrating its effectiveness in bridging the gap between natural language and visual data, which is crucial for text-guided 3D model generation. The final part of the chapter is devoted to examining various forms of 3D data representation, such as Meshes, Point-Clouds, and Voxels. Understanding these representations is key to comprehending the structural makeup of 3D objects in computational settings.

//TODO check Final Diffusion Model

\input{chapters/Basics/VAEs}
\input{chapters/Basics/GANs}
\input{chapters/Basics/diffusionModels}
\input{chapters/Basics/CLIP}
\input{chapters/Basics/MLP}
\input{chapters/Basics/3Drepresentation}
