\chapter{Basics}\label{ch:basics}

This chapter provides the groundwork necessary for the comparative analysis of automatic 3D model generation techniques by introducing the key technologies that drive these methods. It is essential to have a common understanding of the 2D generative models and 3D data representations that form the basis of this field.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.4\columnwidth]{figures/BasicTrilemma.png}
  \caption{The Generative Learning Trilemma: Balancing Quality, Speed, and Diversity in Generative Models.~\citep{xiao2022tackling}}~\label{fig:generativeTrilemma}
\end{figure}

The chapter starts with a brief overview of the most common generative text-to-2D models, as they play a central role in the process of 3D synthesis. The section aims to shed light on the ``generative learning trilemma'', a concept introduced in Figure~\ref{fig:generativeTrilemma} by \citeauthor{xiao2022tackling} that describes the balance between quality, speed and diversity in different generative models. The chapter includes Variational Autoencoders (VAEs) \citep{kingmaVAE,rezendeVAE}, which provide a basic probabilistic framework for learning complex data representations while balancing fast sampling and diversity in their results. Following this, Generative Adversarial Networks (GANs) \citep{goodfellowGAN} are presented, highlighting their fast training mechanisms for producing high-quality samples that include both generator and discriminator components. In addition, the chapter explores the area of diffusion models, which are characterized by diversity and sample quality. A particular focus is on Denoising Diffusion Probabilistic Models (DDPMs) \citep{hoDDPMs,sohlDDPM}, while Stochastic Gradient Methods (SGMs) \citep{song2019SGM} and Stochastic Differential Equations (SDEs) \citep{song2020score,song2021maximum} are also addressed. 

Furthermore, the chapter deals with Contrastive Language-Image Pre-training (CLIP) \citep{radfordCLIP} and illustrates its effectiveness in bridging the gap between natural language and visual data, which is crucial for text-driven 3D model generation. Additionally, the architecture of basic Multilayer Perceptrons (MLPs) are briefly described. The final part of the chapter is dedicated to exploring different forms of 3D data representation, such as meshes, point clouds, and voxels, as well as some more efficient methods for representing 3D models, e.g., NeRFs, DMTets, and InstantNGP\@. Understanding these representations is key to understanding the structural makeup of 3D objects in computational environments.


\input{chapters/Basics/VAEs}
\input{chapters/Basics/GANs}
\input{chapters/Basics/diffusionModels}
\input{chapters/Basics/CLIP}
\input{chapters/Basics/MLP}
\input{chapters/Basics/3Drepresentation}
