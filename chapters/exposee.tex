\chapter{Exposé}
\label{ch:exposé}

The ability to recreate our surroundings in great detail is a worthwhile effort that can be used in many situations and significantly enhance our day-to-day existence. For instance, it enables us to produce vast quantities of diverse assets quickly and efficiently, which are essential in the creation of movies and video games. Moreover, it allows the development of realistic simulations that are invaluable for training pilots in a simulated cockpit, allowing surgeons to practice complex procedures on virtual patients, and aiding architects in designing and testing buildings within a virtual environment. Being able to generate highly precise 3D objects quickly is essential for such endeavors.\\ 
My bachelor thesis focuses on exploring the techniques and fundamentals of automatic 3D model generation, comparing different methods and highlighting their unique approaches and advantages or limitations. I will try to solve the following research questions:\\
What are the capabilities of Automatic 3D Model Generation?
What is the current state of the art?
How could they be used and/or improved?
\\
The thesis begins with an introduction to the fundamental concepts including Generative Adversarial Networks (GANs) \citep{goodfellow2020generative} and diffusion models \citep{yang2022diffusion} and how they can be used for automatic 3D model generation.  I will then discuss in detail the current state of the art, including DreamFusion \citep{poole2022dreamfusion}, Point-e \citep{nichol2022point}, and other recent or future models \citep{xu2022dream3d,lin2022magic3d}, addressing their potential use cases or limitations. After establishing a basic knowledge of this Topic, I will attempt to evaluate possible ideas for future improvements and enhancements that could further strengthen the ability of current models to generate high-quality 3D Objects.\\
\\
Some of the literature that will benefit the creation of my thesis:\\
\textbf{\cite{yang2022diffusion}}\\
Yang et al. provide a comprehensive overview of diffusion models and their variants such as DDPMs, SGMs, or score SDEs. The authors start with an easy-to-understand explanation of the basic concepts and structure of diffusion models and continue their contribution by showing some possible applications of such models. Diffusion models find their use in computer vision, natural language generation and also multi-modal generation, which I will mainly focus on in my bachelor thesis. The article concludes with a summary of the current state of the art and future research directions in diffusion models.\\
\\
\textbf{\cite{goodfellow2020generative}}\\
The paper provides an overview of generative adversarial networks (GANs), a deep learning technique. GANs utilize the probability distribution of a training set obtained from generative models and further apply this information to create new similar data that resembles the given set.\\
\textbf{\cite{mildenhall2021nerf}}\\
In this article, the structure of Neural Radiance Fields (NeRFs) is explained in detail, which is a crucial aspect of my thesis. Most of the state-of-the-art models, which will be presented in my thesis, are based on NeRFs, making this article one of the main resources I will use.\\
\textbf{\cite{poole2022dreamfusion}}\\
The paper introduces DreamFusion, a novel approach for 3D synthesis of text using a unique volumetric representation. This technique employs a text-to-image diffusion model to generate 2D images of a desired object from various angles and then merges the resulting images into a new 3D model using another diffusion model. By utilizing this method, DreamFusion enables the creation of high-quality, visually appealing 3D models from textual descriptions.\\
\textbf{\cite{nichol2022point}}\\
The paper introduces Point-E, a new method for producing point clouds through the utilization of a neural network which involves generating 3D point clouds from a probability density function learned in 3D space. While this approach significantly reduces the time required for model creation, it comes at the cost of limited level of detail.\\
\textbf{\cite{lin2022magic3d}}\\
The authors show a solution to the drawbacks of DreamFusions, as the original approach is very time consuming. Their newly developed tool Magic3D allows to speed up the production of a model by half while also being more precise.\\
\textbf{\cite{xu2022dream3d}}\\
Dream3D is a method which provides even more detailed results in zero-shot-text-guided synthesis as the CLIP-guided 3D optimization methods like DreamFields or PureCLIPNeRF. They achieve this by introducing explicit 3D shape priors into the CLIP-guided 3D optimization process. Dream3D is capable of generating imaginative 3D content with better visual quality and shape accuracy than state-of-the-art methods.\\














