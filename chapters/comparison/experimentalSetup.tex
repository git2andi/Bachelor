\section{Experimental Setup}\label{Setup}

3D model generation is a demanding task, both in terms of computational power and hardware resources. Each method has unique requirements, which poses a significant challenge in creating a fair baseline for comparative analysis.

To address this, the novel project Threestudio \citep{threestudio2023} was utilized. This platform provides slightly adapted versions of the official methods, preserving their core functionality while making them more accessible for systems with limited hardware capabilities. For example, the standard requirements for running Magic123 \citep{qian2023magic123} include a V100 GPU with about 32GB of RAM\@. Threestudio, however, modifies this to work with a T4 GPU, which has around 16GB of RAM\@. This adaptation is crucial for ensuring uniform testing conditions across different methods, allowing for an equitable comparison without the constraints of high-end hardware requirements. The specifics of Threestudio's modifications compared to the original implementations are detailed in their GitHub documentation \citep{threestudio2023}.

Despite Threestudio's advancements, hardware limitations remain a prevalent hurdle. During the course of this thesis, the available hardware was a single NVIDIA GeForce RTX 2080 GPU with 8GB of RAM\@. To circumvent this limitation, Google Colab \citep{googlecolab} was utilized, offering the ability to run code and access free GPUs. This solution, however, came with its own set of restrictions, notably the limitation to single-GPU usage. This was a notable drawback, considering that most 3D modeling methods typically benefit from multi-GPU training, often with as many as eight V100 GPUs, to yield more detailed results and faster computation times. Table 1 in this section provides a stark comparison of the training duration for each method across different iteration counts, highlighting the vast differences between personal hardware capabilities and those used in the official implementations by the original authors. Another notable limitation of Google Colab is the unpredictability regarding the duration for which a Notebook can be used before the runtime is reset. Opting for the premium version of Colab can mitigate this issue by providing more stable runtime, but this comes at the cost of a subscription fee.

The specific test conditions formed the basis for the comparative study. In this phase, each model was trained for 10,000 iterations using a single T4 GPU in Google Colab with the High-Ram setting enabled. Notably, Threestudio provided a testing Colab Notebook with an initial implementation for DreamFusion. This setup was further refined and expanded upon myself to enhance its functionality. Changes to the original Threestudio notebook included the ability to download the complete training folder, which contains important elements such as checkpoints, validation images, configuration details and outputs. The customized version allows this folder to be transferred to a personal Google Drive, ensuring easy access and storage of data. In addition, this enhanced notebook now includes comprehensive code snippets for training, refining and exporting each model beyond the scope of Dreamfusion. The need for slight variations in dependencies for different methods often leads to computational errors. To tackle this, the setup was further modified by integrating additional packages. These adjustments, along with instructions for manual code adjustments, help to mitigate common error messages. An important addition to this experimental setup is the inclusion of the Evaluate3D project, an small initiative developed to facilitate basic geometric comparisons of object files. This tool will be discussed in more detail in section 4.2. However, it is important to point out that the utility of this notebook is highly based on the implementation guidelines provided by Threestudio.

