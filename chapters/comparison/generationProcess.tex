\section{Individual Generation Process}\label{generationProcess}

If not mentioned differently, each model was trained for 10,000 iterations using a single T4 GPU in Google Colab with the High-Ram setting enabled. It is important to note that this hardware configuration does not match the specifications used in the official implementations of these models. Consequently, the results generated in this study may not be as detailed and precise. Despite these limitations, the primary purpose here is to evaluate the basic capabilities of each model, which is possible even with comparatively modest hardware standards.

To effectively demonstrate the generation process of each method, an example prompt was used: ``a robot made of plants''. The choice of this prompt was strategic as concept of a robot is inherently versatile and does not have a rigid definition in terms of appearance or composition. Furthermore, it was assumed that a simple prompt such as ``a robot'' would lead to bland and colorless models, reflecting the results observed when applying such a prompt to a text-to-image model, specifically Dall-E 3 \citep{dalle3, Dall-E-3}. To mitigate this, the phrase ``made out of plants'' was added. This not only countered the potential monotony of the models, but also tested the models' ability to represent intricate detail and incorporate color, particularly the various hues associated with plants. The expectation was that this addition would enrich the output of the models and provide a more comprehensive basis for evaluating their detail rendering capabilities.

\input{chapters/comparison/generationDreamFusion.tex}
\input{chapters/comparison/generationMagic3D.tex}
\input{chapters/comparison/generationFantasia3D.tex}
\input{chapters/comparison/generationMagic123.tex}
\input{chapters/comparison/generationWonder3D.tex}
